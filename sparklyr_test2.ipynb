{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Testing Spark + `sparklyr` - part 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "\n",
    "- [Kickstart](#Kickstart)\n",
    "- [Uploading the data in JSON format](#Uploading-the-data-in-JSON-format)\n",
    "- [Install libraries in SparkR](#Install-libraries-in-SparkR)\n",
    "- [Spark and R in Jupyter](#Spark-and-R-in-Jupyter)\n",
    "    - [Configuring Spark and R](#Configuring-Spark-and-R)\n",
    "    - [Loading spark context (RDDs)](#Loading-spark-context-(RDDs)\n",
    "- [Reading JSON into Spark context: `reviews_Books_5.json`](#Reading-JSON-into-Spark-context:-reviews_Books_5.json)\n",
    "    - [Prepare dataset](#Prepare-dataset)\n",
    "    - [Split Data](#Split-Data)\n",
    "    - [Binarize - dichotomize](#Binarize---dichotomize)\n",
    "    - [Tokenize](#Tokenize)\n",
    "    - [Remove stop-words](#Remove-stop-words)\n",
    "    - [Fit data](#Fit-data)\n",
    "    - [Predict](#Predict)\n",
    "    - [Plot data](#Plot-data)\n",
    "- [Session](#Session)\n",
    "    - [Paths recognised by sparkR](#Paths-recognised-by-sparkR)\n",
    "    - [R session info](#R-session-info)\n",
    "- [References](#References)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kickstart"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See the [pyspark course](https://github.com/javicacheiro/pyspark_course/blob/master/unit_1_tools.ipynb) here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Uploading the data in JSON format "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we need to upload our data from our HOME to the HDFS home directory.  \n",
    "- You can add a single file, or an entire folder.\n",
    "- You can also list or delete files, folders."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    $ hdfs dfs -put /mnt/gluster/...../data/jscars.json .\n",
    "      # list data\n",
    "      hdfs dfs -ls\n",
    "      # deleting files, folders\n",
    "      hdfs dfs -rm -r -f data/jscars.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install libraries in SparkR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before all, enter `sparkR` from your HOME directory:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    $ sparkR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, install the libraries as needed. When you finish, exit the interactive `sparkR` session."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    > install.packages(c(\"sparklyr\", \"dplyr\", \"knitr\", \"ggplot2\", \"repr\")\n",
    "    > q()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spark and R in Jupyter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuring Spark and R "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add this variable to .bashrc to avoid setting `Sys.setenv` in `R`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    $ cd $HOME\n",
    "      export R_PROFILE_USER=/usr/hdp/2.4.2.0-258/spark/R/lib/SparkR/profile/shell.R\n",
    "      source .bashrc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set `R` environment variables (needed for Jupyter notebooks in the cluster `sparkR` installation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Sys.setenv(SPARK_HOME='/usr/hdp/2.4.2.0-258/spark') # commented after being added to .bashrc\n",
    ".libPaths(c(file.path(Sys.getenv('SPARK_HOME'), 'R', 'lib'), .libPaths()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<ol>\n",
       "\t<li>TRUE</li>\n",
       "\t<li>TRUE</li>\n",
       "\t<li>TRUE</li>\n",
       "\t<li>TRUE</li>\n",
       "\t<li>TRUE</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate}\n",
       "\\item TRUE\n",
       "\\item TRUE\n",
       "\\item TRUE\n",
       "\\item TRUE\n",
       "\\item TRUE\n",
       "\\end{enumerate}\n"
      ],
      "text/markdown": [
       "1. TRUE\n",
       "2. TRUE\n",
       "3. TRUE\n",
       "4. TRUE\n",
       "5. TRUE\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[[1]]\n",
       "[1] TRUE\n",
       "\n",
       "[[2]]\n",
       "[1] TRUE\n",
       "\n",
       "[[3]]\n",
       "[1] TRUE\n",
       "\n",
       "[[4]]\n",
       "[1] TRUE\n",
       "\n",
       "[[5]]\n",
       "[1] TRUE\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x <- c(\"sparklyr\", \"dplyr\", \"knitr\", \"ggplot2\", \"repr\")\n",
    "lapply(x, require, character.only = TRUE, quietly = TRUE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading spark context (RDDs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Currently there are three types of contexts:\n",
    "\n",
    "- Local context: \n",
    "    - Interactive. \n",
    "    - If the user exits session, the tasks are terminated (use `screen` to run after session close).\n",
    "    - All processes reside in the LOGIN node (drivers and executors).\n",
    "    - Can only be used for tasks that require very few resources.\n",
    "- YARN-client: \n",
    "    - Interactive.\n",
    "    - If the user exits session, the tasks are terminated (use `screen` to run after session close).\n",
    "    - The driver resides in the LOGIN node, but the executors are in the CLUSTER nodes. Thus, executors can use all the memory available for the task in the CLUSTER nodes.\n",
    "    - Can be used for memory-intensive tasks.\n",
    "- YARN-cluster:\n",
    "    - Not interactive.\n",
    "    - Both the driver and the executors reside in the CLUSTER nodes.\n",
    "    - Can be used for memory-intensive tasks.\n",
    "    - Currenty doesn't seem available for this version of `R/sparklyr`.\n",
    "    \n",
    "Defining a new context (`sc`) overwrites the previous one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Initiating spark context: yarn (for loading bigger datasets)\n",
    "sc <- spark_connect(master = \"yarn-client\", spark_home = \"/usr/hdp/2.4.2.0-258/spark\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can disable warnings with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "options(warn = -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading JSON into Spark context: `reviews_Books_5.json`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use a [dataset of Amazon Product Data](http://snap.stanford.edu/data/amazon/productGraph/categoryFiles/reviews_Books_5.json.gz) [1] that contains 8.9M book reviews from Amazon, spanning May 1996 - July 2014.\n",
    "\n",
    "Dataset characteristics:\n",
    "\n",
    "- Number of reviews: 8.9M\n",
    "- Size: 8.8GB (uncompressed)\n",
    "- HDFS blocks: 70 (each with 3 replicas)\n",
    "\n",
    "[1] Image-based recommendations on styles and substitutes J. McAuley, C. Targett, J. Shi, A. van den Hengel SIGIR, 2015 http://jmcauley.ucsd.edu/data/amazon/.  \n",
    "\n",
    "I am translating into R the following tutorial: Sentiment analysis with Spark ML. [Material for Machine Learning Workshop Galicia 2016](http://nbviewer.jupyter.org/github/javicacheiro/machine_learning_galicia_2016/blob/master/notebooks/sentiment_analysis-amazon_books.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "books <- spark_read_json(sc, name = \"books\", path = \"amazon/reviews_Books_5.json\") \n",
    "# very big dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "# Source:   lazy query [?? x 9]\n",
       "# Database: spark_connection\n",
       "        asin    helpful overall\n",
       "       <chr>     <list>   <dbl>\n",
       "1 000100039X <list [2]>       5\n",
       "2 000100039X <list [2]>       5\n",
       "3 000100039X <list [2]>       5\n",
       "4 000100039X <list [2]>       5\n",
       "5 000100039X <list [2]>       5\n",
       "6 000100039X <list [2]>       5\n",
       "# ... with 6 more variables: reviewText <chr>, reviewTime <chr>,\n",
       "#   reviewerID <chr>, reviewerName <chr>, summary <chr>, unixReviewTime <dbl>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "head(books)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$asin\n",
      "$asin$name\n",
      "[1] \"asin\"\n",
      "\n",
      "$asin$type\n",
      "[1] \"StringType\"\n",
      "\n",
      "\n",
      "$helpful\n",
      "$helpful$name\n",
      "[1] \"helpful\"\n",
      "\n",
      "$helpful$type\n",
      "[1] \"ArrayType(LongType,true)\"\n",
      "\n",
      "\n",
      "$overall\n",
      "$overall$name\n",
      "[1] \"overall\"\n",
      "\n",
      "$overall$type\n",
      "[1] \"DoubleType\"\n",
      "\n",
      "\n",
      "$reviewText\n",
      "$reviewText$name\n",
      "[1] \"reviewText\"\n",
      "\n",
      "$reviewText$type\n",
      "[1] \"StringType\"\n",
      "\n",
      "\n",
      "$reviewTime\n",
      "$reviewTime$name\n",
      "[1] \"reviewTime\"\n",
      "\n",
      "$reviewTime$type\n",
      "[1] \"StringType\"\n",
      "\n",
      "\n",
      "$reviewerID\n",
      "$reviewerID$name\n",
      "[1] \"reviewerID\"\n",
      "\n",
      "$reviewerID$type\n",
      "[1] \"StringType\"\n",
      "\n",
      "\n",
      "$reviewerName\n",
      "$reviewerName$name\n",
      "[1] \"reviewerName\"\n",
      "\n",
      "$reviewerName$type\n",
      "[1] \"StringType\"\n",
      "\n",
      "\n",
      "$summary\n",
      "$summary$name\n",
      "[1] \"summary\"\n",
      "\n",
      "$summary$type\n",
      "[1] \"StringType\"\n",
      "\n",
      "\n",
      "$unixReviewTime\n",
      "$unixReviewTime$name\n",
      "[1] \"unixReviewTime\"\n",
      "\n",
      "$unixReviewTime$type\n",
      "[1] \"LongType\"\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# sdf_schema(books)\n",
    "print(sdf_schema(books))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here I used the Hive function `rpad` to truncate the variable `reviewText` to 30 characters. This allows for a correct display of the table.  \n",
    "See more Hive functions in the [**References**](#References) section below. And also [this](http://www.folkstalk.com/2011/11/string-functions-in-hive.html):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "\n",
       "|reviewText_trunc               | overall|\n",
       "|:------------------------------|-------:|\n",
       "|Spiritually and mentally inspi |       5|\n",
       "|This is one my must have books |       5|\n",
       "|This book provides a reflectio |       5|\n",
       "|I first read THE PROPHET in co |       5|\n",
       "|A timeless classic.  It is a v |       5|\n",
       "|Reading this made my mind feel |       5|"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "books %>%\n",
    "  mutate(reviewText_trunc = as.character(rpad(reviewText, 30, '...'))) %>%\n",
    "  select(reviewText_trunc, overall) %>% \n",
    "  head() %>%\n",
    "  kable()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "\n",
       "| overall|       n|\n",
       "|-------:|-------:|\n",
       "|       1|  323833|\n",
       "|       2|  415110|\n",
       "|       3|  955189|\n",
       "|       4| 2223094|\n",
       "|       5| 4980815|"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "books %>%\n",
    "  group_by(overall) %>%\n",
    "  count() %>%\n",
    "  arrange(overall) %>%\n",
    "  collect() %>%\n",
    "  kable()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Prepare dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "We will avoid neutral reviews by keeping only reviews with 1 or 5 stars overall score. We will also filter out the reviews that contain no text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nonneutral_reviews <- books %>%\n",
    "  filter(overall == 1 | overall == 5) %>%\n",
    "  filter(reviewText != '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nonneutral_reviews %>%\n",
    "  collect() %>%\n",
    "  head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binarize - dichotomize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove stop-words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Session "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paths recognised by sparkR "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    ".libPaths()\n",
    "Sys.getenv(\"R_HOME\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### R session info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "R version 3.3.2 (2016-10-31)\n",
       "Platform: x86_64-pc-linux-gnu (64-bit)\n",
       "Running under: CentOS Linux 7 (Core)\n",
       "\n",
       "locale:\n",
       " [1] LC_CTYPE=es_ES.UTF-8       LC_NUMERIC=C              \n",
       " [3] LC_TIME=es_ES.UTF-8        LC_COLLATE=es_ES.UTF-8    \n",
       " [5] LC_MONETARY=es_ES.UTF-8    LC_MESSAGES=es_ES.UTF-8   \n",
       " [7] LC_PAPER=es_ES.UTF-8       LC_NAME=C                 \n",
       " [9] LC_ADDRESS=C               LC_TELEPHONE=C            \n",
       "[11] LC_MEASUREMENT=es_ES.UTF-8 LC_IDENTIFICATION=C       \n",
       "\n",
       "attached base packages:\n",
       "[1] stats     graphics  grDevices utils     datasets  methods   base     \n",
       "\n",
       "other attached packages:\n",
       "[1] repr_0.10      ggplot2_2.2.0  knitr_1.15.1   dplyr_0.7.1    sparklyr_0.5.6\n",
       "[6] SparkR_1.6.1  \n",
       "\n",
       "loaded via a namespace (and not attached):\n",
       " [1] Rcpp_0.12.8      plyr_1.8.4       highr_0.6        dbplyr_1.1.0    \n",
       " [5] bindr_0.1        base64enc_0.1-3  tools_3.3.2      digest_0.6.10   \n",
       " [9] uuid_0.1-2       gtable_0.2.0     jsonlite_1.1     evaluate_0.10   \n",
       "[13] tibble_1.3.3     pkgconfig_2.0.1  rlang_0.1.1      IRdisplay_0.4.4 \n",
       "[17] shiny_1.0.3      DBI_0.7          rstudioapi_0.6   IRkernel_0.7.1  \n",
       "[21] yaml_2.1.14      parallel_3.3.2   bindrcpp_0.2     withr_1.0.2     \n",
       "[25] httr_1.2.1       stringr_1.1.0    grid_3.3.2       rprojroot_1.1   \n",
       "[29] glue_1.1.1       R6_2.2.0         pbdZMQ_0.2-4     magrittr_1.5    \n",
       "[33] scales_0.4.1     backports_1.0.4  htmltools_0.3.5  assertthat_0.1  \n",
       "[37] colorspace_1.3-1 mime_0.5         xtable_1.8-2     httpuv_1.3.3    \n",
       "[41] labeling_0.3     config_0.2       stringi_1.1.2    lazyeval_0.2.0  \n",
       "[45] munsell_0.4.3    crayon_1.3.2    "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sessionInfo()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References \n",
    "\n",
    "- [`sparklyr` tutorial](http://spark.rstudio.com/).\n",
    "- [`sparklyr` cheatsheet](http://spark.rstudio.com/images/sparklyr-cheatsheet.pdf).\n",
    "- [`sparklyr`: creating extensions](http://spark.rstudio.com/extensions.html).\n",
    "- [Differences between `sparkr` and `sparklyr`](https://stackoverflow.com/questions/39494484/sparkr-vs-sparklyr)..\n",
    "- [Hive Operators and UDFs](https://cwiki.apache.org/confluence/display/Hive/LanguageManual+UDF)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.3.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
